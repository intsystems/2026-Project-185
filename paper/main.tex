\documentclass{article}

\PassOptionsToPackage{numbers, sort, compress}{natbib}
\usepackage[main,final]{neurips_2025}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}

%%%

\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{manyfoot}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{listings}

\newtheorem{theorem}{Theorem} % continuous numbers
%%\newtheorem{theorem}{Theorem}[section] % sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
\newtheorem{lemma}{Lemma}% 
%%\newtheorem{proposition}{Proposition} % to get separate numbers for theorem and proposition etc.

\newtheorem{example}{Example}
\newtheorem{remark}{Remark}

\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}

%%%


\title{TEMPO: EM-Based Mixture-of-PODs for Operator Learning}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{
  Rodion Akinzhala\\
  MIPT\\
  Moscow, Russia\\
  \And
  Alexander Terentyev (Consultant)\\
  MIPT\\
  Moscow, Russia\\
  \And
  Vadim Strijov (Advisor)\\
  MIPT\\
  Moscow, Russia\\
}


\begin{document}


\maketitle

\begin{abstract}
    Operator learning addresses the approximation of mappings between function spaces, which commonly arise in the solution of partial differential equations (PDEs) governing physical systems. Deep Operator Networks (DeepONet) learn such operators through branch and trunk neural networks. POD-DeepONet improves upon this by replacing the trunk network with Proper Orthogonal Decomposition (POD) bases derived from solution snapshots, achieving superior accuracy and training efficiency.
However, existing POD-DeepONet methods employ a single global basis across all parameters, which proves insufficient when solutions exhibit regime-dependent behavior such as laminar-turbulent transitions or diffusion-reaction regime changes. We propose TEMPO (EM-based Mixture-of-PODs), an adaptive framework combining Expectation-Maximization clustering with multiple regime-specific POD bases. Gaussian Mixture Models automatically discover distinct dynamical regimes by partitioning solution snapshots in a low-dimensional POD coefficient space. For each discovered regime, we construct locally optimal POD bases that efficiently capture regime-specific solution features.
The architecture employs multiple regime-conditioned branch networks, each paired with its corresponding POD basis, coordinated through a learned gating network that produces probabilistic mixture weights for smooth regime transitions. This approach enables automatic regime discovery without manual partitioning, achieves superior local approximation through specialized bases, and provides parametric adaptivity where regime selection depends on input conditions. We validate the framework on benchmark PDEs exhibiting multi-regime phenomena, demonstrating significant improvements over standard POD-DeepONet for complex operators.
\end{abstract}

\textbf{Keywords:} Operator learning, DeepONet, Proper Orthogonal Decomposition, Expectation-Maximization, Gaussian mixture models, Regime discovery

\section{Introduction}\label{sec:intro}

TODO

\textbf{Contributions.} Our contributions can be summarized as follows:
\begin{itemize}
    \item We present...
    \item We demonstrate the validity of our theoretical results through empirical studies...
    \item We highlight the implications of our findings for...
\end{itemize}

\textbf{Outline.} The rest of the paper is organized as follows...

\section{Related Work}\label{sec:rw}

\textbf{Topic \#1.}
TODO

\textbf{Topic \#2.}
TODO

\section{Preliminaries}\label{sec:prelim}

\subsection{General notation}

In this section, we introduce the general notation used in the rest of the paper and the basic assumptions. 

\subsection{Assumptions} 

TODO

\section{Method}\label{sec:method}

\section{Experiments}\label{sec:exp}

To verify the theoretical estimates obtained, we conducted a detailed empirical study...

\section{Discussion}\label{sec:disc}

TODO

\section{Conclusion}\label{sec:concl}

TODO


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{unsrtnat}
\bibliography{references}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\appendix
\section{Appendix / supplemental material}\label{app}

\subsection{Additional experiments / Proofs of Theorems}\label{app:exp}

TODO

\end{document}